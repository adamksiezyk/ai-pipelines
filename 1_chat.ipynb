{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6da0be-703c-4214-9e22-a7863e4d9670",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b5a12-93e3-4ca1-aea1-5b8ca833a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0820a-8300-4d65-9244-3f5fcdc2ae80",
   "metadata": {},
   "source": [
    "### Connect to LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162f0ed-2091-43dd-beea-3758c792ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8080/v1\",\n",
    "    api_key=\"dev\",\n",
    "    model=\"mistral\",\n",
    "    temperature=0,\n",
    "    max_tokens=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6102a40-0e3b-442d-80d6-561ea0fefaea",
   "metadata": {},
   "source": [
    "### Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15dfdb-2a36-43da-a9d0-34f9f3efd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm.invoke([\n",
    "    SystemMessage(\"You are an AI assistant, that helps people write pirate poems\"),\n",
    "    HumanMessage(\"What is a sentence transformer model?\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b571e9-8e7b-4296-b27e-9d64ae215880",
   "metadata": {},
   "source": [
    "### Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff712a-c7d9-4ca6-a450-eb957efeea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_llm.stream([\n",
    "    SystemMessage(\"You are an AI assistant, that helps people write pirate poems\"),\n",
    "    HumanMessage(\"Hello!\"),\n",
    "])\n",
    "for token in response:\n",
    "    print(token.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e66f1-53dc-461c-b827-b11ec6ebcedc",
   "metadata": {},
   "source": [
    "### Chat with history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ea469-8b0b-405c-ad3d-c5178b3649ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're an assistant who's good at math. Respond in 20 words or fewer\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | chat_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ca7d0-c7a7-407c-9be8-a9de06e06c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "chat_with_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689373ca-cea7-4173-a46a-ecb6ab6165a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_history.invoke(\n",
    "    {\"input\": \"Ahoy! What's 2+2?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552dd00-5966-4c35-b538-6e7ffeb841e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_history.invoke(\n",
    "    {\"input\": \"Could you repeat?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2dac0-a82c-40ef-be38-96fff9611974",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_quit_token = \"q\"\n",
    "session_restart_token = \"n\"\n",
    "session_id = 0\n",
    "print(\"Chat with Mistral-7B-Instruct.\")\n",
    "print(f\"- type {session_quit_token!r} to quit\")\n",
    "print(f\"- type {session_restart_token!r} for a new session\")\n",
    "print(\"Enter your prompt:\\n\")\n",
    "while (query := input(\"> \")) != session_quit_token:\n",
    "    if query == session_restart_token:\n",
    "        print(\"Starting new session.\\n\")\n",
    "        session_id += 1\n",
    "        continue\n",
    "\n",
    "    response = chat_with_history.stream(\n",
    "        {\"input\": query},\n",
    "        config={\"configurable\": {\"session_id\": session_id}},\n",
    "    )\n",
    "    for token in response:\n",
    "        print(token.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-coe-webinar",
   "language": "python",
   "name": "ai-coe-webinar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
